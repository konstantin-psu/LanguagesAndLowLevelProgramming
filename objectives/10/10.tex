\documentclass{article}

\usepackage{fancyhdr}
\usepackage{extramarks}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{tikz}
\usepackage[plain]{algorithm}
\usepackage{algpseudocode}
\usepackage{enumerate}

\usepackage{listings}
\usepackage{xcolor}
\usepackage{forest}
\usepackage[shortlabels]{enumitem}
\setlist[enumerate, 1]{1\textsuperscript{o}}
\lstset { %
    language=bash,
        backgroundcolor=\color{black!5}, % set backgroundcolor
            basicstyle=\footnotesize,% basic font setting
}

%\usetikzlibrary{automata,positioning}
\usetikzlibrary{positioning,shapes,shadows,arrows,automata}

%
% Basic Document Settings
%

\topmargin=-0.45in
\evensidemargin=0in
\oddsidemargin=0in
\textwidth=6.5in
\textheight=9.0in
\headsep=0.25in

\linespread{1.1}

\pagestyle{fancy}
\lhead{\hmwkAuthorName}
\rhead{ (\hmwkClassInstructor\ \hmwkClassTime): \hmwkTitle}
\lfoot{\lastxmark}
\cfoot{\thepage}

\renewcommand\headrulewidth{0.4pt}
\renewcommand\footrulewidth{0.4pt}

\setlength\parindent{0pt}

\setcounter{secnumdepth}{0}
\newcounter{partCounter}


\newcommand{\hmwkTitle}{Portfolio submission, Topic 10}
\newcommand{\hmwkDueDate}{June 3, 2016}
\newcommand{\hmwkClass}{CS510 Languages and Low Level Programming}
\newcommand{\hmwkClassTime}{Spring 2016}
\newcommand{\hmwkClassInstructor}{Mark P. Jones}
\newcommand{\hmwkAuthorName}{Konstantin Macarenco}


\title{
    \vspace{2in}
    \textmd{\textbf{\hmwkClass:\ \hmwkTitle}}\\
        \normalsize\vspace{0.1in}\small{Due\ on\ \hmwkDueDate\ at 11:59pm}\\
        \vspace{0.1in}\large{\textit{\hmwkClassInstructor\ \hmwkClassTime}}
    \vspace{3in}
}

\author{\textbf{\hmwkAuthorName}}
\date{}

\renewcommand{\part}[1]{\textbf{\large Part \Alph{partCounter}}\stepcounter{partCounter}\\}

\begin{document}

\maketitle

\pagebreak

%\begin{enumerate}[(a), leftmargin = 0.7cm, nosep]
        \section{Topic 10.  Use practical case studies to evaluate and compare language design proposals.}

%STARTSTART

        With the lack of specific language for Low Level Programming, I picked two languages with
        Parallel Programming in mind (General C + MPI library, and Chapel - new domain specific
        language for parallel programming created by Cray).  Even though domain is different it
        shows that language designed for a specific domain can drastically aid applications
        development.
        Parallel programming complexity is similar, if not greater than
        LLP, with many potential issues on the top of regular mistakes there are Concurrency Issues
        such as race conditions, and deadlocks.
        MPI - message passing interface is a well known standard for external parallel computing.
        Chapel - is build upon C/MPI is much simpler - it is a modern high level language that hides
        all the intricacies of Message Passing. Chapel syntax is similar to Python, with many alike
        features. Chapel uses C/MPI as an intermediate layer, i.e. first it compiles to C.\\
    
        I Compare implementation of Jacobi-Laplace algorithm in C/MPI vs Chapel. 
        
        Jacobi-Laplace is a
        simple approach for solving Laplace equation with $O(n^3)$ complexity, used in many
        scientific applications. As $n\rightarrow \infty$ performance is greatly reduced, hence the
        desire to run it in parallel mode.\\
        Laplace equation : 
        ${\phi^{t+1}}_{i,j} = \cfrac{1}{4} ({\phi^{t}}_{i+1,j} + {\phi^{t}}_{i-1,j} +
        {\phi^{t}}_{i,j+1} + {\phi^{t}}_{i,j-1}), 0 < i, j< N$ , i.e. current cell in a matrix is
        equal to a quarter of the sum of it's neighboring cells.\\
    
        External implementation requires matrix partitioning, and message passing when computing
        border elements.\\
        
        \textbf{Implementation comparison chart - next page.}

        \textbf{Both implementations are included to the submission} 
        

        \begin{itemize}
            \item laplace-mpi.c - C/MPI
            \item chapel-distr.chpl - Chapel
            \item Makefile
            \item laplace-distr.c - Chapel Generated code (not to be compiled or executed).
            \item chpl-prep - Environment setup for running chapel appliactions
            \item mpi-prep - Environment setup required for running MPI applications
        \end{itemize}
        \textbf{Building and running instructions}:\\ 
        
        The code intended to be build on linuxlab machines.
        \begin{lstlisting}
make
# MPI -
    source mpi-prep && mpirun -n 4 laplace_mpi  # number of remote procs must be 4 for 
        this application
# Chapel
    source chpl-prep && ./laplace-distr -nl [number of remote procs] # number of 
        procs can not exceed 20 
        \end{lstlisting}

        \pagebreak

        \begin{centering}
        \begin{table}[h!]
            \centering
            \caption{Languages comparison}
            \label{my-label}
            \begin{tabular}{l| p{7.5cm} | p{7.5cm}} \hline
              Types             &  C/MPI & Chapel \\ \hline
              Complexity    & 
                    High. It is quite a challenging task to do int C/MPI, since matrix
                    mapping to the network done manually, and all communications are manual as well.
                    The particular implementation I use as an example, divides matrix to 4 regions,
                    each region is then sent to a remote CPU. It would be even more challenging to 
                    implement dynamic scalable matrix partitioning.  &  

                    Low. As easy as implementing sequential version, just need to
                        specify domain mapping. Chapel sequential and MPI implementations are almost
                        identical, with one exception - matrix needs to be mapped to the distributed
                        cluster. This is a natively supported operation in Chapel, short and
                        concise. Unlike C doesn't require any math, or matrix offsets calculation.
                        Code is simple and easy to read. Chapel includes multiple flexible
                        partitioning schemes, and also allows custom definition. The problem is
                        mapped automatically depending on the number of the available remote CPUs.
                    
                    \\ \hline
              Error Prone  &  
                    No. C doesn't provide much help in error detection, or debugging, if
                        in case of any fault, especially related to race conditions
                
                &  
                    Yes. Chapel can detect common programming error such as division by zero, out of 
                    index, etc.
                \\ \hline
              Effort     &  
                    High.  
                &  
                    Low.
                \\ \hline
              Code Size     &   
                    Large $\approx 620\ lines$ with comments
                
                &  
                    Small $\approx 60\ lines$ with comments
                \\ \hline
                
              Performance   
                & High. Area where C shines is performance. C implementation is up to x40 times
                faster.
                & Low. At this point of time Chapel suffers from performance issues. It is a new
                language, that is still undergoing major development, so code produce by chapel
                compiler is far from being optimal. For example generated C code is $\approx 3K$
                lines long, besides the size, generated code is far from being optimal.

            \end{tabular}
        \end{table}
        \end{centering}

        In conclusion: this comparison clearly demonstrates how usage of domain specific language
        can simplify the problem and increase developing performance.


%ENDEND
\end{document}
